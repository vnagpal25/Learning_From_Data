{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf5ed8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63c783d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting/visualization\n",
    "def set_cartesian_plane():\n",
    "    ax = plt.figure().add_subplot(1, 1, 1)\n",
    "    ax.spines['left'].set_position('center')\n",
    "    ax.spines['bottom'].set_position('center')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([-1.5, 1.5])\n",
    "\n",
    "def generate_target_function():\n",
    "    # generate two random points\n",
    "    p1 = np.random.uniform(-1, 1, size=2)\n",
    "    p2 = np.random.uniform(-1, 1, size=2)\n",
    "    \n",
    "    # Using points to get the parameters m and c for y = mx + c\n",
    "    m = (p1[1] -p2[1])/(p1[0] - p2[0]) # m = (y1 - y2)/ (x1 -x2)\n",
    "    c = p1[1] - m*p1[0] # c = y - mx   \n",
    "    \n",
    "    w_target = np.array([c, m, -1])\n",
    "    \n",
    "    return w_target\n",
    "\n",
    "def run_linear_regression(X, y):\n",
    "    pinv_X = np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T)\n",
    "    w = np.dot(pinv_X, y)# w = pseudo_inv(X)*y \n",
    "    return w\n",
    "\n",
    "#This method is meant to return the pseudo inverse of the matrix X\n",
    "def pseudo_inv(X):\n",
    "    Xt = np.transpose(X)\n",
    "    XtX = np.dot(Xt, X)\n",
    "    XtX_inv = np.linalg.inv(XtX)\n",
    "    pinv_X = np.dot(XtX_inv, Xt)\n",
    "    return pinv_X\n",
    "\n",
    "\n",
    "# this method returns the same matrix with ones concatenated\n",
    "def getInputX(x_vals):\n",
    "    X = x_vals\n",
    "#     X = X.reshape(1, X.size)\n",
    "    X = np.transpose(X)\n",
    "    ones = np.ones((1,N_points))\n",
    "    X = np.concatenate((ones, X), axis = 0) # concatenate ones to account for bias term\n",
    "    X = np.transpose(X)# X= vector containing points input x as its rows\n",
    "    return X\n",
    "\n",
    "def classify(point, w):\n",
    "    return np.sign(np.dot(point, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52e77c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average in-sample error:  0.03917000000000009\n"
     ]
    }
   ],
   "source": [
    "'''QUESTION 5'''\n",
    "N_experiments= 1000\n",
    "N_points = 100\n",
    "g_list = [] # keeps a list of all the final hypotheses\n",
    "target_function_list = [] # keep a list of all of the target functions for linear classification\n",
    "E_in_list = [] # keeps a list of all of the in sample errors of the LSRLs for classifying points\n",
    "\n",
    "\n",
    "\n",
    "for i in range(N_experiments):\n",
    "    w_target = generate_target_function()\n",
    "    \n",
    "    # generate specified number of random points\n",
    "    x_n = np.random.uniform(-1, 1, size=(N_points, 2))\n",
    "\n",
    "    #concantenate ones as the first column, bias term\n",
    "    X = getInputX(x_n)\n",
    "    \n",
    "    # taking dot product of N x 3 point array and 3 x 1 weights array to get N x 1 classifications\n",
    "    # this is basically checking the sign of c + mx -y. \n",
    "    # If this is positive, then point is under the line. ( y < mx + c)\n",
    "    # If this is negative, then the point is above the line. (y > mx + c)\n",
    "    y = np.sign(np.dot(X, w_target)) # ground truth classification\n",
    "    \n",
    "    # compute linear regression weights vector\n",
    "    w = run_linear_regression(X, y)\n",
    "    \n",
    "    # classification predictions from linear regression\n",
    "    y_lr = np.sign(np.dot(X, w))\n",
    "    \n",
    "    E_in = sum(y_lr != y) / N_points # calculating in sample error\n",
    "\n",
    "    E_in_list.append(E_in)\n",
    "    g_list.append(w)\n",
    "    target_function_list.append(w_target)\n",
    "    \n",
    "E_in_avg = sum(E_in_list)/len(E_in_list)\n",
    "print(\"Average in-sample error: \", E_in_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae3a3cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average out of sample error over 1000 trials:  0.049127999999999984\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "QUESTION 6\n",
    "'''\n",
    "N_experiments= 1000\n",
    "N_test_points = 1000\n",
    "E_out_list = []\n",
    "for i, final_hyp in enumerate(g_list):\n",
    "    target_function = target_function_list[i]\n",
    "    x_test_points = np.concatenate((np.ones((N_test_points, 1)), \n",
    "                                    np.random.uniform(-1, 1, size=(N_test_points, 2))), \n",
    "                                    axis = 1)\n",
    "    y_actual = np.sign(np.dot(x_test_points, target_function))\n",
    "    y_predicted = np.sign(np.dot(x_test_points, final_hyp))\n",
    "    \n",
    "    E_out = sum(y_actual != y_predicted) / N_test_points # calculating out of sample error\n",
    "    \n",
    "    E_out_list.append(E_out)\n",
    "\n",
    "E_out_avg = sum(E_out_list)/len(E_out_list)\n",
    "print('Average out of sample error over 1000 trials: ', E_out_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53a6ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of iterations to converge PLA using Linear Regression as initial weights:  3.638\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "QUESTION 7\n",
    "'''\n",
    "N_points = 10\n",
    "N_experiments = 1000\n",
    "iterations_list = []\n",
    "for i in range(N_experiments):\n",
    "    # generating a random target function\n",
    "    w_target = generate_target_function()\n",
    "    \n",
    "    # generating random points with bias term\n",
    "    x_n = np.concatenate((np.ones((N_points, 1)), np.random.uniform(-1, 1, size=(N_points, 2))), axis = 1)\n",
    "    \n",
    "    #classifying according to target\n",
    "    y_actual = np.sign(np.dot(x_n, w_target))\n",
    "    \n",
    "    # getting weights from linear regression, will serve as initial weights for perceptron learning algorithm(PLA)\n",
    "    w_regression = run_linear_regression(x_n, y_actual)\n",
    "    \n",
    "    #\n",
    "    y_predicted = np.sign(np.dot(x_n, w_regression))\n",
    "    \n",
    "    iterations = 0\n",
    "    # the perceptron algorithm will run until all the points are classified correctly\n",
    "    while not sum(y_predicted != y_actual) == 0:\n",
    "        \n",
    "        iterations += 1 # keep track of amount of iterations of PLA\n",
    "        \n",
    "        correctNs = [] # points correctly classified\n",
    "        incorrectNs = [] # points misclassified\n",
    "        \n",
    "        for n, point in enumerate(x_n):\n",
    "            if(y_predicted[n] == y_actual[n]):\n",
    "                correctNs.append(n)\n",
    "            else:\n",
    "                incorrectNs.append(n)\n",
    "        \n",
    "        point_to_update = random.choice(incorrectNs)\n",
    "        for n, weight in enumerate(w_regression):\n",
    "            w_regression[n] += y_actual[point_to_update] * x_n[point_to_update][n]\n",
    "        \n",
    "        \n",
    "        y_predicted = np.sign(np.dot(x_n, w_regression))\n",
    "\n",
    "    iterations_list.append(iterations)\n",
    "\n",
    "print(\"Average number of iterations to converge PLA using Linear Regression as initial weights: \", sum(iterations_list)/len(iterations_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b4bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
