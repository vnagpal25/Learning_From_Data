{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e13699-8134-4264-946a-20f45a7f835c",
   "metadata": {},
   "source": [
    "# Question 1, Answer C\n",
    "##### We can approach this problem by solving the provided equation for $N$ in terms of $\\sigma$, $d$, and $E_D[E_{in}(w_{lin})]$\n",
    "##### By simple algebra, we can arrive at \n",
    "$$ N = \\frac{\\sigma ^2 (d+1)}{\\sigma ^2 - E_D[E_{in}(w_{lin})]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7171961-0b57-413a-bb33-d028cfb64b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A minimum of 45 samples needed to achieve an expected in sample error of 0.008\n",
      "As we can see, out of the answer choice, the smallest number of samples to guarantee an in sample error of at least 0.008 has to be greater than 45. Therefore, the correct answer is C, 100 samples.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "sigma = 0.1\n",
    "d = 8\n",
    "E_in_exp = 0.008\n",
    "\n",
    "N_min = ((sigma ** 2) * (d + 1)) / ( (sigma ** 2) - E_in_exp)\n",
    "print(f'A minimum of {math.ceil(N_min)} samples needed to achieve an expected in sample error of {E_in_exp}')\n",
    "print(f'As we can see, out of the answer choice, the smallest number of samples to guarantee an in sample error of at least {E_in_exp} has to be greater than {math.ceil(N_min)}. Therefore, the correct answer is C, 100 samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bde3a-7aaf-4a72-bd7b-6334737816ec",
   "metadata": {},
   "source": [
    "# Question 2, Answer D\n",
    "\n",
    "##### the hypothesis is of the form: $h(x) = sign(w_0 + w_1x_1^2 + w_2x_2^2)$\n",
    "##### At $(x_1, x_2) = (0, 0)$, the hypothesis should classify the point as +1\n",
    "##### At this point, $h(x) = sign(w_0)$, and if h(x) classifies the point as +1, then $w_0 > 0$\n",
    "##### When $x_1$ is large, and $x_2 = 0$, then the hypothesis should classify the point as -1\n",
    "##### At this point, $h(x) = sign(w_0 + w_1x_1^2) = -1$, this implies that $w_1 < 0$\n",
    "##### When $x_2$ is large, and $x_1 = 0$, then the hypothesis should classify the point as +1\n",
    "##### At this point, $h(x) = sign(w_0 + w_2x_2^2) = +1$, this implies that $w_2 > 0$\n",
    "##### This answer aligns with answer choice D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d3fe6",
   "metadata": {},
   "source": [
    "# Question 3, Answer C\n",
    "##### There are 14 coordinates and 1 bias coordinate in $\\Phi_4$\n",
    "##### This leads to a $d_{vc} = 15$\n",
    "##### The smallest value that is not smaller than the vc dimension is 15 among the answer choices, which is choice C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966da595",
   "metadata": {},
   "source": [
    "# Question 4, Answer E\n",
    "##### $E(u, v) = (ue^v - 2ve^{-u})^2$\n",
    "##### $\\frac{\\partial{E}}{\\partial{u}} = 2(ue^v - 2ve^{-u})(e^v + 2ve^{-u})$\n",
    "##### This corresponds to answer choice E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ef535",
   "metadata": {},
   "source": [
    "# Question 5, Answer D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8053109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 iterations taken for algorithm to converge\n",
      "Therefore the correct answer choice is D\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def E(u, v):\n",
    "    return (u*np.exp(v) - 2*v*np.exp(-u)) ** 2\n",
    "\n",
    "def deltaE(u, v):\n",
    "    partialE_partialu = 2 * (u*np.exp(v) - 2*v*np.exp(-u)) * (np.exp(v) + 2 *v* np.exp(-u))\n",
    "    partialE_partialv = 2 * (u*np.exp(v) - 2*v*np.exp(-u)) * (u*np.exp(v) - 2*np.exp(-u))\n",
    "    return np.array([partialE_partialu, partialE_partialv])\n",
    "\n",
    "eta = 0.1 # learning rate\n",
    "error_thresh = 10 ** -14 # threshold error\n",
    "\n",
    "u, v = (1, 1) # initializing as 1, 1\n",
    "iterations = 0\n",
    "while E(u, v) > error_thresh:\n",
    "    iterations += 1\n",
    "    gradE = deltaE(u, v)\n",
    "    \n",
    "    # update weights vector\n",
    "    u -= eta * gradE[0]\n",
    "    v -= eta * gradE[1]\n",
    "    \n",
    "print(f'{iterations} iterations taken for algorithm to converge')\n",
    "print('Therefore the correct answer choice is D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92291f6d",
   "metadata": {},
   "source": [
    "# Question 6, Answer E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d2aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights: \n",
      "0.045 0.024\n",
      "Therefore the correct answer choice is E\n"
     ]
    }
   ],
   "source": [
    "print('Final Weights: ')\n",
    "print(\"{:.3f}\".format(u), \"{:.3f}\".format(v))\n",
    "print('Therefore the correct answer choice is E')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127039a9",
   "metadata": {},
   "source": [
    "# Question 7, Answer A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a95fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error measure\n",
      "0.13981379199615315\n",
      "Therefore the correct answer choice is A, 0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def E(u, v):\n",
    "    return (u*np.exp(v) - 2*v*np.exp(-u)) ** 2\n",
    "\n",
    "def deltaE(u, v):\n",
    "    partialE_partialu = 2 * (u*np.exp(v) - 2*v*np.exp(-u)) * (np.exp(v) + 2 *v* np.exp(-u))\n",
    "    partialE_partialv = 2 * (u*np.exp(v) - 2*v*np.exp(-u)) * (u*np.exp(v) - 2*np.exp(-u))\n",
    "    return np.array([partialE_partialu, partialE_partialv])\n",
    "\n",
    "eta = 0.1 # learning rate\n",
    "error_thresh = 10 ** -14 # threshold error\n",
    "\n",
    "u, v = (1, 1) # initializing as 1, 1\n",
    "for i in range(15):\n",
    "    gradE = deltaE(u, v)\n",
    "    u -= eta * gradE[0]\n",
    "    gradE = deltaE(u, v)\n",
    "    v -= eta * gradE[1]\n",
    "\n",
    "print('Final error measure')\n",
    "print(E(u, v))\n",
    "print('Therefore the correct answer choice is A, 0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd51cd0",
   "metadata": {},
   "source": [
    "# Question 8, Answer D\n",
    "# Question 9, Answer A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c86a927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean out of sample error, 0.10199060311763469\n",
      "Therefore Answer Choice D is correct\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_experiments = 100\n",
    "N_points = 100\n",
    "N_test_points = 1000\n",
    "eta = 0.01\n",
    "\n",
    "def generate_line():\n",
    "    # generate two random points\n",
    "    p1 = np.random.uniform(-1, 1, size=2)\n",
    "    p2 = np.random.uniform(-1, 1, size=2)\n",
    "    \n",
    "    # Using points to get the parameters m and c for y = mx + c\n",
    "    m = (p1[1] -p2[1])/(p1[0] - p2[0]) # m = (y1 - y2)/ (x1 -x2)\n",
    "    c = p1[1] - m*p1[0] # c = y - mx   \n",
    "    \n",
    "    w_target = np.array([c, m, -1])\n",
    "    \n",
    "    return w_target\n",
    "\n",
    "\n",
    "def get_input_points(num_points):\n",
    "    X = np.random.uniform(-1, 1, size=(num_points, 2))\n",
    "    X = np.transpose(X)\n",
    "    ones = np.ones((1,num_points))\n",
    "    X = np.concatenate((ones, X), axis = 0) # concatenate ones to account for bias term\n",
    "    X = np.transpose(X)# X= vector containing points input x as its rows\n",
    "    return X\n",
    "\n",
    "def generate_dataset(w_target, N_points):\n",
    "    X = get_input_points(N_points)\n",
    "    \n",
    "    y_n = np.sign(np.dot(X, w_target))\n",
    "    \n",
    "    return X, y_n\n",
    "\n",
    "\n",
    "def deltaE(w, x, y):\n",
    "    return (-y * x)/(1 + np.exp(y  * np.dot(w, x)))\n",
    "    \n",
    "def logistic_reg_fit(w_target, X, y_n):\n",
    "    epochs = 0\n",
    "    w = np.zeros(np.shape(w_target))\n",
    "    prev_w = np.ones(np.shape(w_target))\n",
    "    \n",
    "    while True:     \n",
    "        prev_w = w\n",
    "        \n",
    "        for n in np.random.permutation(N_points):\n",
    "            gradE = deltaE(w, X[n,:], y_n[n])\n",
    "            w = w - eta * gradE\n",
    "        \n",
    "        epochs += 1\n",
    "        \n",
    "        if np.linalg.norm(w - prev_w) < 0.01:\n",
    "            break\n",
    "    return w, epochs\n",
    "\n",
    "def cross_entropy_error(w, x, y):\n",
    "    return np.log(1 + np.exp(-y * np.dot(w, x)))\n",
    "\n",
    "\n",
    "def calculate_E_out(w_log_reg, X_test, y_n_test):\n",
    "    point_errs = []\n",
    "    \n",
    "    for point_index in range(X_test.shape[0]):\n",
    "        point_errs.append(cross_entropy_error(w_log_reg, X_test[point_index, :], y_n_test[point_index]))\n",
    "    \n",
    "    E_out = np.mean(point_errs)\n",
    "    return E_out\n",
    "\n",
    "E_out_list = []\n",
    "epochs_list = [] \n",
    "for i in range(N_experiments):\n",
    "    w_target = generate_line()\n",
    "    X, y_n = generate_dataset(w_target, N_points) # get target function and training points\n",
    "\n",
    "    # fitting to training points\n",
    "    w_final, epochs = logistic_reg_fit(w_target, X, y_n)\n",
    "\n",
    "    # test points, cross entropy error\n",
    "    X_test, y_n_test = generate_dataset(w_target, N_test_points)\n",
    "\n",
    "    E_out = calculate_E_out(w_final, X_test, y_n_test)\n",
    "    E_out_list.append(E_out)\n",
    "    epochs_list.append(epochs)\n",
    "\n",
    "print(f'Mean out of sample error, {np.mean(E_out_list)}')\n",
    "print('Therefore, Question 8 Answer Choice D is correct')\n",
    "\n",
    "print(f'Mean number of epochs needed for convergence, {np.mean(epochs_list)}')\n",
    "print('Therefore, Question 9 Answer Choice A is correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e933485d",
   "metadata": {},
   "source": [
    "# Question 10, Answer E\n",
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
