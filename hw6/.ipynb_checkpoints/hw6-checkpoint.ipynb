{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46daf0ee",
   "metadata": {},
   "source": [
    "# Question 1, Answer B\n",
    "###### We know that deterministic noise is a directly related to the complexity of our target function and the ability of the 'best' hypothesis from our Hypotheis Set to approximate that target. It is intuitive to see that as we choose more complex hypothesis sets, the ability for our 'best' hypothesis to approximate the target function increases, therefore our deterministic noise decreases.\n",
    "\n",
    "###### Now, we know that $H' \\subset H$, therefore $H'$ is less complex than $H$. Therefore we know that the best hypothesis from $H'$ will not be able to approximate the target function as well as the best hypothesis from $H$. Therefore the deterministic noise increases if use $H'$ instead of $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e610d",
   "metadata": {},
   "source": [
    "# Question 2, Answer A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c4580ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = np.genfromtxt(file_name)\n",
    "    return data[:, :2], data[:, 2] # X in first two columns, y in last column\n",
    "\n",
    "def non_lin_trans(X):\n",
    "    Z = np.array([(1, point[0], point[1], point[0] ** 2, point[1] ** 2, \n",
    "                   point[0] * point[1], np.absolute(point[0] - point[1]), np.absolute(point[0] + point[1])) for point in X])\n",
    "    return Z\n",
    "\n",
    "def run_linear_regression(Z, y):\n",
    "    ZtZ = np.dot(Z.T, Z)\n",
    "    pinv_Z = np.dot(np.linalg.inv(ZtZ), Z.T)\n",
    "    w = np.dot(pinv_Z, y) # w = pseudo_inv(X)*y \n",
    "    return w\n",
    "\n",
    "def compute_error(w, Z, y):\n",
    "    #for each 'point'/row z in Z, compute wTz and compare sign(wTz) with y\n",
    "     # will contain 0 or 1, for correct/incorrect classification\n",
    "    error_list = [(np.sign(w.T @ z) != y_point) for z, y_point in zip(Z, y)]\n",
    "    return np.sum(error_list)/len(error_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d83c95bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The in-sample error is 0.03, while the out of sample error is 0.08\n",
      "The correct answer choice is A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train = load_data('in.dta')\n",
    "Z_train = non_lin_trans(X_train)# transform data using non linear transformation\n",
    "w_lin = run_linear_regression(Z_train, y_train)# one step learning using linear regression\n",
    "E_in = compute_error(w_lin, Z_train, y_train)\n",
    "\n",
    "X_test, y_test = load_data('out.dta')\n",
    "Z_test = non_lin_trans(X_test)# transform data using non linear transformation\n",
    "E_out = compute_error(w_lin, Z_test, y_test)\n",
    "\n",
    "print(f'The in-sample error is {\"{:.2f}\".format(E_in)}, while the out of sample error is {\"{:.2f}\".format(E_out)}')\n",
    "print('The correct answer choice is A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c40bb",
   "metadata": {},
   "source": [
    "# Question 3, Answer D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd8576ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that takes k as a parameter\n",
    "def run_linear_regression(Z, y, lamda):\n",
    "    _, cols = np.shape(Z)\n",
    "    ZtZ = np.dot(Z.T, Z)\n",
    "    pinv_Z = np.dot(np.linalg.inv(ZtZ + lamda * np.identity(cols)), Z.T)\n",
    "    w = np.dot(pinv_Z, y) # w = pseudo_inv(X)*y \n",
    "    return w    \n",
    "\n",
    "def regularize_lin_reg(k):\n",
    "    lamda = 10 ** k # purposely misspelling lambda because it is a keyword in python\n",
    "    X_train, y_train = load_data('in.dta')\n",
    "    \n",
    "    Z_train = non_lin_trans(X_train)# transform data using non linear transformation\n",
    "    w_lin = run_linear_regression(Z_train, y_train, lamda)# one step learning using linear regression\n",
    "    E_in = compute_error(w_lin, Z_train, y_train)\n",
    "\n",
    "    X_test, y_test = load_data('out.dta')\n",
    "    Z_test = non_lin_trans(X_test)# transform data using non linear transformation\n",
    "    E_out = compute_error(w_lin, Z_test, y_test)\n",
    "    return E_in, E_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44e99111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The in-sample error is 0.03, while the out of sample error is 0.08\n",
      "The correct answer choice is D\n"
     ]
    }
   ],
   "source": [
    "E_in, E_out = regularize_lin_reg(k=-3)\n",
    "print(f'The in-sample error is {\"{:.2f}\".format(E_in)}, while the out of sample error is {\"{:.2f}\".format(E_out)}')\n",
    "print('The correct answer choice is D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b758a",
   "metadata": {},
   "source": [
    "# Question 4, Answer E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2efa09e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The in-sample error is 0.4, while the out of sample error is 0.4\n",
      "The correct answer choice is E\n"
     ]
    }
   ],
   "source": [
    "E_in, E_out = regularize_lin_reg(k=3)\n",
    "print(f'The in-sample error is {\"{:.1f}\".format(E_in)}, while the out of sample error is {\"{:.1f}\".format(E_out)}')\n",
    "print('The correct answer choice is E')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b80994",
   "metadata": {},
   "source": [
    "# Question 5, Answer D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "60d26f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error list: [0.084, 0.056, 0.092, 0.124, 0.228]\n",
      "List of k: [-2, -1, 0, 1, 2]\n",
      "As we can see the minimum out of sample error is E_out = 0.056 for k = -1\n",
      "The correct answer choice is D\n"
     ]
    }
   ],
   "source": [
    "k_s = range(-2, 3)\n",
    "E_list = [regularize_lin_reg(k) for k in k_s]\n",
    "E_out_list = [E[1] for E in E_list]\n",
    "\n",
    "\n",
    "print(f'Error list: {E_out_list}')\n",
    "print(f'List of k: {list(k_s)}')\n",
    "print(f'As we can see the minimum out of sample error is E_out = {E_out_list[1]} for k = {k_s[1]}')\n",
    "print('The correct answer choice is D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f6ea4",
   "metadata": {},
   "source": [
    "# Question 6, Answer B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c84f816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum out of sample error: 0.06\n",
      "The correct answer choice is B\n"
     ]
    }
   ],
   "source": [
    "print(f'Minimum out of sample error: {\"{:.2f}\".format(min(E_out_list))}')\n",
    "print('The correct answer choice is B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4635f70",
   "metadata": {},
   "source": [
    "# Question 7, Answer C\n",
    "##### According to the definition of $H(Q, C, Q_0)$, $H(10, 0, 3)$ will have weights vector $w$ of the form $w = (w_1, w_2, 0, 0, 0, 0, 0, 0, 0, 0)$\n",
    "##### This is equivalent to a weights vector from the hypothesis set $H_2$, which will be of the form $w = (w_1, w_2)$\n",
    "##### Similarly, $H(10, 0, 4)$ will have weights vector $w$ of the form $w = (w_1, w_2, w_3, 0, 0, 0, 0, 0, 0, 0)$\n",
    "##### This is equivalent to a weights vector from the hypothesis set $H_3$, which will be of the form $w = (w_1, w_2, w_3)$\n",
    "\n",
    "##### We can see that any vector in $H_2$ can be generated by $H_4$ by letting $w_3=0$. Therefore, $H_2$ is a subset of $H_3$\n",
    "\n",
    "##### We can not make any generalizations of vectors from sets $H(10, 1, 3)$ or $H(10, 1, 4)$, except that the former set is a subset of the latter set:\n",
    "\n",
    "##### Let $w_a \\epsilon H(10, 1, 3)$. $w_a$ can thus be written as $w_a = (w_1, w_2, 1, 1, 1, 1, 1, 1, 1, 1)$\n",
    "##### Let $w_b \\epsilon H(10, 1, 4)$. $w_b$ can thus be written as $w_b = (w_1, w_2, w_3, 1, 1, 1, 1, 1, 1, 1)$\n",
    "##### $H(10, 1, 3) \\subset H(10, 1, 4)$, however, we can't make any generalizations regarding either of them being related to the definition of $H_Q$\n",
    "\n",
    "##### a. $H_2 \\cup H_3 = H_3$ Since $H_3$ is a superset, so this choice is not correct\n",
    "##### b. as stated earlier, we can't make any generalizations regarding definition of $H_Q$ here\n",
    "##### c. $H_2 \\cap H_3 = H_2$, this is correct\n",
    "##### d. can't make any generalizations again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
